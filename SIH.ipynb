{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359a4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6277928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>market</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>priceflag</th>\n",
       "      <th>pricetype</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>usdprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1994-01-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1994-03-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1994-04-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1994-05-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1994-07-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     admin1           admin2     market   latitude  longitude  \\\n",
       "10   1994-01-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "75   1994-03-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "118  1994-04-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "155  1994-05-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "214  1994-07-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "\n",
       "               category commodity unit priceflag pricetype currency price  \\\n",
       "10   cereals and tubers     Wheat   KG    actual    Retail      INR   7.0   \n",
       "75   cereals and tubers     Wheat   KG    actual    Retail      INR   6.5   \n",
       "118  cereals and tubers     Wheat   KG    actual    Retail      INR   6.5   \n",
       "155  cereals and tubers     Wheat   KG    actual    Retail      INR   4.0   \n",
       "214  cereals and tubers     Wheat   KG    actual    Retail      INR   6.8   \n",
       "\n",
       "    usdprice  \n",
       "10    0.2231  \n",
       "75    0.2073  \n",
       "118   0.2073  \n",
       "155   0.1275  \n",
       "214   0.2168  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wfp_food_prices_ind.csv')\n",
    "df = df[df['admin1']=='Karnataka']\n",
    "df = df[df['commodity']=='Wheat']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105c4df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>market</th>\n",
       "      <th>price</th>\n",
       "      <th>usdprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1994-01-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1994-03-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1994-04-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1994-05-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1994-07-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     admin1           admin2     market price usdprice\n",
       "10   1994-01-15  Karnataka  Bangalore Urban  Bengaluru   7.0   0.2231\n",
       "75   1994-03-15  Karnataka  Bangalore Urban  Bengaluru   6.5   0.2073\n",
       "118  1994-04-15  Karnataka  Bangalore Urban  Bengaluru   6.5   0.2073\n",
       "155  1994-05-15  Karnataka  Bangalore Urban  Bengaluru   4.0   0.1275\n",
       "214  1994-07-15  Karnataka  Bangalore Urban  Bengaluru   6.8   0.2168"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['latitude','longitude','priceflag','currency','category','commodity','unit','pricetype'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b0b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16395292300>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['date'][13:25],df['price'][13:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06f86da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(694, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b31ff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10         7.00\n",
       "75         6.50\n",
       "118        6.50\n",
       "155        4.00\n",
       "214        6.80\n",
       "          ...  \n",
       "172761    44.45\n",
       "172843    44.33\n",
       "172924    44.36\n",
       "173088    44.28\n",
       "173175    44.15\n",
       "Name: price, Length: 694, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b6457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 555 months\n",
      "Validation data: 69 months\n",
      "Test data: 70 months\n"
     ]
    }
   ],
   "source": [
    "data = df['price'].values\n",
    "\n",
    "# Define the split percentages\n",
    "train_size = int(len(data) * 0.8)\n",
    "val_size = int(len(data) * 0.1)\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "# Split the data\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:train_size + val_size]\n",
    "test_data = data[train_size + val_size:]\n",
    "\n",
    "print(f\"Train data: {len(train_data)} months\")\n",
    "print(f\"Validation data: {len(val_data)} months\")\n",
    "print(f\"Test data: {len(test_data)} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad10f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a MinMaxScaler to scale the price data between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape data into a 2D array for the scaler\n",
    "price_scaled = scaler.fit_transform(df['price'].values.reshape(-1, 1))\n",
    "\n",
    "# Convert back to a 1D array\n",
    "price_scaled = price_scaled.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f1d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, window_size=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# For example, if you use the past 12 months to predict the next month's price:\n",
    "window_size = 12\n",
    "X, y = create_dataset(price_scaled, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d080fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = X\n",
    "\n",
    "# Reshaping for LSTM or Conv1D layers (add an extra dimension for features)\n",
    "X_lstm = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426dadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the splits you calculated earlier\n",
    "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d15968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (X): (682, 12)\n",
      "Output shape (y): (682,)\n"
     ]
    }
   ],
   "source": [
    "# Example function to create sliding windows\n",
    "def create_windowed_dataset(data, window_size=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])  # Past 'window_size' values as input\n",
    "        y.append(data[i + window_size])    # Next value as the target output\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Assuming 'price_scaled' is your preprocessed and scaled time series data\n",
    "window_size = 12  # Using 12 months (1 year) of data to predict the next month\n",
    "X, y = create_windowed_dataset(price_scaled, window_size)\n",
    "\n",
    "# Check the shape of the inputs and outputs\n",
    "print(f\"Input shape (X): {X.shape}\")  # Expected: (num_samples, window_size)\n",
    "print(f\"Output shape (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86e5ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm = X.reshape((X.shape[0], X.shape[1], 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb910dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,057</span> (19.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,057\u001b[0m (19.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,057</span> (19.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,057\u001b[0m (19.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Dense model architecture\n",
    "def build_dense_model(window_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Input layer (takes input of shape `window_size`)\n",
    "    model.add(layers.InputLayer(input_shape=(window_size,)))\n",
    "    \n",
    "    # First hidden layer with 64 neurons and ReLU activation\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # Second hidden layer with 64 neurons and ReLU activation\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # Output layer (single neuron, no activation for regression)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: assuming window_size is 12\n",
    "window_size = 12\n",
    "dense_model = build_dense_model(window_size)\n",
    "\n",
    "# Summary of the model architecture\n",
    "dense_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef0960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1893 - mae: 0.3400 - val_loss: 0.0440 - val_mae: 0.1998\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146 - mae: 0.1000 - val_loss: 0.0166 - val_mae: 0.1132\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mae: 0.0520 - val_loss: 0.0042 - val_mae: 0.0479\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - mae: 0.0434 - val_loss: 0.0054 - val_mae: 0.0550\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0040 - val_mae: 0.0440\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - mae: 0.0402 - val_loss: 0.0040 - val_mae: 0.0444\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0039 - val_mae: 0.0438\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0037 - val_mae: 0.0428\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0039 - val_mae: 0.0437\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - mae: 0.0400 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0036 - val_mae: 0.0421\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0035 - val_mae: 0.0417\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0036 - val_mae: 0.0418\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0343 - val_loss: 0.0040 - val_mae: 0.0449\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.0036 - val_mae: 0.0423\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0354 - val_loss: 0.0036 - val_mae: 0.0427\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0354 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.0040 - val_mae: 0.0454\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0349 - val_loss: 0.0040 - val_mae: 0.0454\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0037 - val_mae: 0.0433\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0040 - val_mae: 0.0459\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0356 - val_loss: 0.0035 - val_mae: 0.0422\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0335 - val_loss: 0.0034 - val_mae: 0.0421\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0343 - val_loss: 0.0037 - val_mae: 0.0443\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0350 - val_loss: 0.0042 - val_mae: 0.0473\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 0.0036 - val_mae: 0.0428\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 0.0039 - val_mae: 0.0451\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0036 - val_mae: 0.0431\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0346 - val_loss: 0.0034 - val_mae: 0.0421\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0337 - val_loss: 0.0034 - val_mae: 0.0430\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0359 - val_loss: 0.0036 - val_mae: 0.0426\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0348 - val_loss: 0.0036 - val_mae: 0.0436\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0322 - val_loss: 0.0034 - val_mae: 0.0422\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 0.0036 - val_mae: 0.0435\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0344 - val_loss: 0.0038 - val_mae: 0.0445\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0341 - val_loss: 0.0035 - val_mae: 0.0422\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 0.0034 - val_mae: 0.0421\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0340 - val_loss: 0.0036 - val_mae: 0.0431\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0034 - val_mae: 0.0417\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0351 - val_loss: 0.0036 - val_mae: 0.0436\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0322 - val_loss: 0.0040 - val_mae: 0.0457\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0323 - val_loss: 0.0043 - val_mae: 0.0485\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0349 - val_loss: 0.0034 - val_mae: 0.0434\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0033 - val_mae: 0.0415\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0036 - val_mae: 0.0434\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0314 - val_loss: 0.0034 - val_mae: 0.0434\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0043 - val_mae: 0.0482\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0034 - val_mae: 0.0417\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.0041 - val_mae: 0.0466\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.0034 - val_mae: 0.0429\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0357 - val_loss: 0.0038 - val_mae: 0.0453\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0035 - val_mae: 0.0443\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0331 - val_loss: 0.0039 - val_mae: 0.0454\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0036 - val_mae: 0.0441\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0340 - val_loss: 0.0034 - val_mae: 0.0415\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0349 - val_loss: 0.0033 - val_mae: 0.0420\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0335 - val_loss: 0.0034 - val_mae: 0.0417\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.0044 - val_mae: 0.0490\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.0034 - val_mae: 0.0419\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 0.0033 - val_mae: 0.0415\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0339 - val_loss: 0.0034 - val_mae: 0.0417\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0314 - val_loss: 0.0037 - val_mae: 0.0442\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0352 - val_loss: 0.0033 - val_mae: 0.0416\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.0053 - val_mae: 0.0559\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0033 - val_mae: 0.0416\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0051 - val_mae: 0.0546\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.0035 - val_mae: 0.0450\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0342 - val_loss: 0.0041 - val_mae: 0.0465\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0033 - val_mae: 0.0426\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.0046 - val_mae: 0.0512\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0336 - val_loss: 0.0033 - val_mae: 0.0420\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0037 - val_mae: 0.0438\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0034 - val_mae: 0.0415\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0035 - val_mae: 0.0424\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0034 - val_mae: 0.0420\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0041 - val_mae: 0.0470\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0035 - val_mae: 0.0429\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0035 - val_mae: 0.0448\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0033 - val_mae: 0.0418\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0043 - val_mae: 0.0485\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0316 - val_loss: 0.0040 - val_mae: 0.0468\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0347 - val_loss: 0.0033 - val_mae: 0.0419\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0034 - val_mae: 0.0417\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0041 - val_mae: 0.0471\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0035 - val_mae: 0.0429\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0033 - val_mae: 0.0427\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0054 - val_mae: 0.0562\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0035 - val_mae: 0.0430\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0038 - val_mae: 0.0452\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0336 - val_loss: 0.0035 - val_mae: 0.0429\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.0053 - val_mae: 0.0561\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0046 - val_mae: 0.0510\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0342 - val_loss: 0.0035 - val_mae: 0.0427\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0035 - val_mae: 0.0432\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0040 - val_mae: 0.0461\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0038 - val_mae: 0.0447\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 0.0033 - val_mae: 0.0418\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0033 - val_mae: 0.0418\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0476 \n",
      "Test MAE: 0.04754054918885231\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are the preprocessed input and output data\n",
    "history = dense_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = dense_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8bcdf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "def build_lstm_model(window_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # LSTM layer with 50 units (neurons)\n",
    "    model.add(layers.LSTM(50, activation='relu', input_shape=(window_size, 1)))\n",
    "    \n",
    "    # Optionally, you can add more LSTM layers here\n",
    "    # model.add(layers.LSTM(50, activation='relu', return_sequences=False))\n",
    "    \n",
    "    # Dense output layer (1 neuron for predicting the next time step's value)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model with Adam optimizer and MSE loss function\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: Assuming window_size is 12 (12 months), input shape will be (12, 1)\n",
    "window_size = 12\n",
    "lstm_model = build_lstm_model(window_size)\n",
    "\n",
    "# Summary of the model\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f63fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.3256 - mae: 0.5181 - val_loss: 0.4545 - val_mae: 0.6705\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1682 - mae: 0.3615 - val_loss: 0.1567 - val_mae: 0.3909\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0330 - mae: 0.1455 - val_loss: 0.0033 - val_mae: 0.0394\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0081 - mae: 0.0762 - val_loss: 0.0035 - val_mae: 0.0420\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - mae: 0.0617 - val_loss: 0.0036 - val_mae: 0.0409\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0527 - val_loss: 0.0038 - val_mae: 0.0424\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0447 - val_loss: 0.0049 - val_mae: 0.0534\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0429 - val_loss: 0.0071 - val_mae: 0.0709\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0045 - val_mae: 0.0509\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0036 - val_mae: 0.0411\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0046 - val_mae: 0.0530\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0035 - val_mae: 0.0407\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - mae: 0.0421 - val_loss: 0.0038 - val_mae: 0.0436\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0035 - val_mae: 0.0410\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0035 - val_mae: 0.0401\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0036 - val_mae: 0.0421\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0037 - val_mae: 0.0426\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0382 - val_loss: 0.0035 - val_mae: 0.0408\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0034 - val_mae: 0.0400\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0036 - val_mae: 0.0421\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0407 - val_loss: 0.0034 - val_mae: 0.0401\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0035 - val_mae: 0.0406\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0034 - val_mae: 0.0402\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0035 - val_mae: 0.0415\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0034 - val_mae: 0.0401\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0395 - val_loss: 0.0035 - val_mae: 0.0421\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0409 - val_loss: 0.0034 - val_mae: 0.0414\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0034 - val_mae: 0.0399\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0038 - val_mae: 0.0439\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0039 - val_mae: 0.0443\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0397 - val_loss: 0.0034 - val_mae: 0.0398\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0369 - val_loss: 0.0034 - val_mae: 0.0402\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0033 - val_mae: 0.0396\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0048 - val_mae: 0.0521\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0034 - val_mae: 0.0401\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0033 - val_mae: 0.0395\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0378 - val_loss: 0.0041 - val_mae: 0.0460\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0403 - val_loss: 0.0035 - val_mae: 0.0416\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0035 - val_mae: 0.0413\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.0034 - val_mae: 0.0399\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0036 - val_mae: 0.0417\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0411 - val_loss: 0.0035 - val_mae: 0.0410\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0036 - val_mae: 0.0421\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0395 - val_loss: 0.0052 - val_mae: 0.0550\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0420 - val_loss: 0.0033 - val_mae: 0.0397\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0397 - val_loss: 0.0033 - val_mae: 0.0400\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0382 - val_loss: 0.0041 - val_mae: 0.0460\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0036 - val_mae: 0.0441\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0038 - val_mae: 0.0436\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0382 - val_loss: 0.0034 - val_mae: 0.0405\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0408 - val_loss: 0.0033 - val_mae: 0.0402\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0389 - val_loss: 0.0033 - val_mae: 0.0402\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0367 - val_loss: 0.0033 - val_mae: 0.0401\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0043 - val_mae: 0.0478\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0034 - val_mae: 0.0403\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0035 - val_mae: 0.0414\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0035 - val_mae: 0.0408\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0375 - val_loss: 0.0039 - val_mae: 0.0446\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0043 - val_mae: 0.0481\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0411 - val_loss: 0.0047 - val_mae: 0.0512\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0042 - val_mae: 0.0467\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0035 - val_mae: 0.0407\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0382 - val_loss: 0.0033 - val_mae: 0.0395\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0034 - val_mae: 0.0405\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0037 - val_mae: 0.0428\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0081 - val_mae: 0.0744\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0033 - val_mae: 0.0404\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0379 - val_loss: 0.0033 - val_mae: 0.0406\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0376 - val_loss: 0.0037 - val_mae: 0.0427\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0388 - val_loss: 0.0033 - val_mae: 0.0397\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0392 - val_loss: 0.0033 - val_mae: 0.0398\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0399 - val_loss: 0.0033 - val_mae: 0.0402\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0042 - val_mae: 0.0468\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0033 - val_mae: 0.0411\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0033 - val_mae: 0.0411\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0403 - val_loss: 0.0036 - val_mae: 0.0424\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0041 - val_mae: 0.0465\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0367 - val_loss: 0.0033 - val_mae: 0.0399\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0033 - val_mae: 0.0399\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0034 - val_mae: 0.0400\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0376 - val_loss: 0.0033 - val_mae: 0.0400\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0046 - val_mae: 0.0508\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0400 - val_loss: 0.0061 - val_mae: 0.0617\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0413 - val_loss: 0.0041 - val_mae: 0.0458\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0038 - val_mae: 0.0436\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0034 - val_mae: 0.0406\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0382 - val_loss: 0.0046 - val_mae: 0.0506\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0036 - val_mae: 0.0417\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0037 - val_mae: 0.0428\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0043 - val_mae: 0.0479\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0374 - val_loss: 0.0036 - val_mae: 0.0425\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0033 - val_mae: 0.0405\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0407 - val_loss: 0.0035 - val_mae: 0.0412\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0378 - val_loss: 0.0045 - val_mae: 0.0494\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mae: 0.0530 \n",
      "Test MAE: 0.05413557589054108\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are preprocessed and windowed for LSTM input\n",
    "history = lstm_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = lstm_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcbeff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train, X_val, and X_test for LSTM input\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val_lstm = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d12891ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m16,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,293</span> (63.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,293\u001b[0m (63.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,293</span> (63.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,293\u001b[0m (63.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Conv1D model architecture\n",
    "def build_conv1d_model(window_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Conv1D layer with 64 filters, kernel size of 2, and ReLU activation\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(window_size, 1)))\n",
    "    \n",
    "    # MaxPooling1D layer to reduce dimensionality (optional)\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Flatten the output before feeding into Dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Dense hidden layer with 50 units and ReLU activation\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    \n",
    "    # Output layer (1 neuron for predicting the next time step's value)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model with Adam optimizer and MSE loss\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: Assuming window_size is 12 (12 months)\n",
    "window_size = 12\n",
    "conv1d_model = build_conv1d_model(window_size)\n",
    "\n",
    "# Summary of the model\n",
    "conv1d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "083f93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1473 - mae: 0.3186 - val_loss: 0.0151 - val_mae: 0.1130\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0974 - val_loss: 0.0130 - val_mae: 0.0993\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0037 - val_mae: 0.0420\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0440 - val_loss: 0.0061 - val_mae: 0.0604\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0042 - val_mae: 0.0464\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0411 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0040 - val_mae: 0.0450\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0395 - val_loss: 0.0043 - val_mae: 0.0469\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0366 - val_loss: 0.0036 - val_mae: 0.0418\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0042 - val_mae: 0.0461\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0395 - val_loss: 0.0035 - val_mae: 0.0417\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0376 - val_loss: 0.0041 - val_mae: 0.0458\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0039 - val_mae: 0.0438\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0039 - val_mae: 0.0444\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0403 - val_loss: 0.0037 - val_mae: 0.0420\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0039 - val_mae: 0.0437\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0410 - val_loss: 0.0037 - val_mae: 0.0424\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0381 - val_loss: 0.0036 - val_mae: 0.0417\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0042 - val_mae: 0.0463\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0396 - val_loss: 0.0037 - val_mae: 0.0419\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0036 - val_mae: 0.0415\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0397 - val_loss: 0.0037 - val_mae: 0.0425\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0036 - val_mae: 0.0415\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0035 - val_mae: 0.0415\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0398 - val_loss: 0.0039 - val_mae: 0.0441\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0394 - val_loss: 0.0052 - val_mae: 0.0547\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.0037 - val_mae: 0.0421\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0053 - val_mae: 0.0554\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0037 - val_mae: 0.0427\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0042 - val_mae: 0.0466\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0036 - val_mae: 0.0416\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 0.0036 - val_mae: 0.0419\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0046 - val_mae: 0.0497\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0378 - val_loss: 0.0042 - val_mae: 0.0466\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0039 - val_mae: 0.0445\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0036 - val_mae: 0.0419\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0054 - val_mae: 0.0561\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0036 - val_mae: 0.0420\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0037 - val_mae: 0.0423\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0045 - val_mae: 0.0488\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0042 - val_mae: 0.0467\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0035 - val_mae: 0.0421\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0036 - val_mae: 0.0419\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0036 - val_mae: 0.0420\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0041 - val_mae: 0.0461\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0039 - val_mae: 0.0441\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0038 - val_mae: 0.0436\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0040 - val_mae: 0.0450\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0036 - val_mae: 0.0420\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0373 - val_loss: 0.0039 - val_mae: 0.0439\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0359 - val_loss: 0.0035 - val_mae: 0.0420\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0035 - val_mae: 0.0421\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0374 - val_loss: 0.0039 - val_mae: 0.0443\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0382 - val_loss: 0.0036 - val_mae: 0.0421\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0384 - val_loss: 0.0037 - val_mae: 0.0426\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0039 - val_mae: 0.0441\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0417 - val_loss: 0.0045 - val_mae: 0.0491\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0036 - val_mae: 0.0422\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0367 - val_loss: 0.0045 - val_mae: 0.0492\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0035 - val_mae: 0.0421\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0038 - val_mae: 0.0439\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0045 - val_mae: 0.0487\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0041 - val_mae: 0.0463\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0046 - val_mae: 0.0500\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0371 - val_loss: 0.0037 - val_mae: 0.0427\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0049 - val_mae: 0.0524\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0035 - val_mae: 0.0429\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0036 - val_mae: 0.0424\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 0.0039 - val_mae: 0.0448\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0039 - val_mae: 0.0442\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0041 - val_mae: 0.0458\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0036 - val_mae: 0.0424\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0374 - val_loss: 0.0038 - val_mae: 0.0433\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0357 - val_loss: 0.0036 - val_mae: 0.0429\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0036 - val_mae: 0.0426\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0036 - val_mae: 0.0428\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0401 - val_loss: 0.0043 - val_mae: 0.0475\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0040 - val_mae: 0.0450\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0372 - val_loss: 0.0044 - val_mae: 0.0481\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0356 - val_loss: 0.0036 - val_mae: 0.0426\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0040 - val_mae: 0.0452\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0035 - val_mae: 0.0433\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0358 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0371 - val_loss: 0.0039 - val_mae: 0.0445\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0051 - val_mae: 0.0536\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0398 - val_loss: 0.0036 - val_mae: 0.0427\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0361 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0044 - val_mae: 0.0481\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0368 - val_loss: 0.0039 - val_mae: 0.0444\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0368 - val_loss: 0.0036 - val_mae: 0.0429\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0370 - val_loss: 0.0036 - val_mae: 0.0429\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0482 \n",
      "Test MAE: 0.049033023416996\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are preprocessed and windowed for Conv1D input\n",
    "history = conv1d_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = conv1d_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b9da0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train, X_val, and X_test for Conv1D input\n",
    "X_train_conv1d = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val_conv1d = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test_conv1d = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e7a4cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001639D21BA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001639D21BA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Dense Model - MAE: 0.047540543651252244, MSE: 0.0037062280868187217, RMSE: 0.06087879833586338, R2: -0.06042995812985974\n",
      "LSTM Model - MAE: 0.05413557160514438, MSE: 0.004228311895917605, RMSE: 0.06502547113183883, R2: -0.20980913794667\n",
      "Conv1D Model - MAE: 0.04903301956089254, MSE: 0.003744184844008011, RMSE: 0.0611897445983231, R2: -0.07129018623620187\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return mae, mse, rmse, r2\n",
    "\n",
    "# Assuming y_test and y_pred are available for each model\n",
    "# Example for Dense model\n",
    "y_pred_dense = dense_model.predict(X_test)\n",
    "mae_dense, mse_dense, rmse_dense, r2_dense = calculate_metrics(y_test, y_pred_dense)\n",
    "\n",
    "# Example for LSTM model\n",
    "y_pred_lstm = lstm_model.predict(X_test)\n",
    "mae_lstm, mse_lstm, rmse_lstm, r2_lstm = calculate_metrics(y_test, y_pred_lstm)\n",
    "\n",
    "# Example for Conv1D model\n",
    "y_pred_conv1d = conv1d_model.predict(X_test)\n",
    "mae_conv1d, mse_conv1d, rmse_conv1d, r2_conv1d = calculate_metrics(y_test, y_pred_conv1d)\n",
    "\n",
    "# Print or store the results for comparison\n",
    "print(f\"Dense Model - MAE: {mae_dense}, MSE: {mse_dense}, RMSE: {rmse_dense}, R2: {r2_dense}\")\n",
    "print(f\"LSTM Model - MAE: {mae_lstm}, MSE: {mse_lstm}, RMSE: {rmse_lstm}, R2: {r2_lstm}\")\n",
    "print(f\"Conv1D Model - MAE: {mae_conv1d}, MSE: {mse_conv1d}, RMSE: {rmse_conv1d}, R2: {r2_conv1d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71604449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
