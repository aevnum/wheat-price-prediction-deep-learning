{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359a4c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 23:25:35.427722: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6277928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/3c44mc6d1csd1kdh861sc_xh0000gp/T/ipykernel_15628/3079750901.py:1: DtypeWarning: Columns (4,5,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('wfp_food_prices_ind.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>market</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>commodity</th>\n",
       "      <th>unit</th>\n",
       "      <th>priceflag</th>\n",
       "      <th>pricetype</th>\n",
       "      <th>currency</th>\n",
       "      <th>price</th>\n",
       "      <th>usdprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1994-01-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1994-03-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1994-04-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1994-05-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1994-07-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>12.962299</td>\n",
       "      <td>77.576943</td>\n",
       "      <td>cereals and tubers</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>KG</td>\n",
       "      <td>actual</td>\n",
       "      <td>Retail</td>\n",
       "      <td>INR</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     admin1           admin2     market   latitude  longitude  \\\n",
       "10   1994-01-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "75   1994-03-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "118  1994-04-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "155  1994-05-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "214  1994-07-15  Karnataka  Bangalore Urban  Bengaluru  12.962299  77.576943   \n",
       "\n",
       "               category commodity unit priceflag pricetype currency price  \\\n",
       "10   cereals and tubers     Wheat   KG    actual    Retail      INR   7.0   \n",
       "75   cereals and tubers     Wheat   KG    actual    Retail      INR   6.5   \n",
       "118  cereals and tubers     Wheat   KG    actual    Retail      INR   6.5   \n",
       "155  cereals and tubers     Wheat   KG    actual    Retail      INR   4.0   \n",
       "214  cereals and tubers     Wheat   KG    actual    Retail      INR   6.8   \n",
       "\n",
       "    usdprice  \n",
       "10    0.2231  \n",
       "75    0.2073  \n",
       "118   0.2073  \n",
       "155   0.1275  \n",
       "214   0.2168  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wfp_food_prices_ind.csv')\n",
    "df = df[df['admin1']=='Karnataka']\n",
    "df = df[df['commodity']=='Wheat']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105c4df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>market</th>\n",
       "      <th>price</th>\n",
       "      <th>usdprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1994-01-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1994-03-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1994-04-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1994-05-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1994-07-15</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.2168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     admin1           admin2     market price usdprice\n",
       "10   1994-01-15  Karnataka  Bangalore Urban  Bengaluru   7.0   0.2231\n",
       "75   1994-03-15  Karnataka  Bangalore Urban  Bengaluru   6.5   0.2073\n",
       "118  1994-04-15  Karnataka  Bangalore Urban  Bengaluru   6.5   0.2073\n",
       "155  1994-05-15  Karnataka  Bangalore Urban  Bengaluru   4.0   0.1275\n",
       "214  1994-07-15  Karnataka  Bangalore Urban  Bengaluru   6.8   0.2168"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['latitude','longitude','priceflag','currency','category','commodity','unit','pricetype'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b0b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1681335d0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['date'][13:25],df['price'][13:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06f86da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(694, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b31ff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10         7.00\n",
       "75         6.50\n",
       "118        6.50\n",
       "155        4.00\n",
       "214        6.80\n",
       "          ...  \n",
       "172761    44.45\n",
       "172843    44.33\n",
       "172924    44.36\n",
       "173088    44.28\n",
       "173175    44.15\n",
       "Name: price, Length: 694, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b6457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 555 months\n",
      "Validation data: 69 months\n",
      "Test data: 70 months\n"
     ]
    }
   ],
   "source": [
    "data = df['price'].values\n",
    "\n",
    "# Define the split percentages\n",
    "train_size = int(len(data) * 0.8)\n",
    "val_size = int(len(data) * 0.1)\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "# Split the data\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:train_size + val_size]\n",
    "test_data = data[train_size + val_size:]\n",
    "\n",
    "print(f\"Train data: {len(train_data)} months\")\n",
    "print(f\"Validation data: {len(val_data)} months\")\n",
    "print(f\"Test data: {len(test_data)} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad10f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a MinMaxScaler to scale the price data between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Reshape data into a 2D array for the scaler\n",
    "price_scaled = scaler.fit_transform(df['price'].values.reshape(-1, 1))\n",
    "\n",
    "# Convert back to a 1D array\n",
    "price_scaled = price_scaled.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f1d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, window_size=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# For example, if you use the past 12 months to predict the next month's price:\n",
    "window_size = 12\n",
    "X, y = create_dataset(price_scaled, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d080fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = X\n",
    "\n",
    "# Reshaping for LSTM or Conv1D layers (add an extra dimension for features)\n",
    "X_lstm = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "426dadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the splits you calculated earlier\n",
    "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d15968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (X): (682, 12)\n",
      "Output shape (y): (682,)\n"
     ]
    }
   ],
   "source": [
    "# Example function to create sliding windows\n",
    "def create_windowed_dataset(data, window_size=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])  # Past 'window_size' values as input\n",
    "        y.append(data[i + window_size])    # Next value as the target output\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Assuming 'price_scaled' is your preprocessed and scaled time series data\n",
    "window_size = 12  # Using 12 months (1 year) of data to predict the next month\n",
    "X, y = create_windowed_dataset(price_scaled, window_size)\n",
    "\n",
    "# Check the shape of the inputs and outputs\n",
    "print(f\"Input shape (X): {X.shape}\")  # Expected: (num_samples, window_size)\n",
    "print(f\"Output shape (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86e5ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm = X.reshape((X.shape[0], X.shape[1], 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb910dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushikesh/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,057</span> (19.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,057\u001b[0m (19.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,057</span> (19.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,057\u001b[0m (19.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Dense model architecture\n",
    "def build_dense_model(window_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Input layer (takes input of shape `window_size`)\n",
    "    model.add(layers.InputLayer(input_shape=(window_size,)))\n",
    "    \n",
    "    # First hidden layer with 64 neurons and ReLU activation\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # Second hidden layer with 64 neurons and ReLU activation\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # Output layer (single neuron, no activation for regression)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: assuming window_size is 12\n",
    "window_size = 12\n",
    "dense_model = build_dense_model(window_size)\n",
    "\n",
    "# Summary of the model architecture\n",
    "dense_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ef0960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0892 - mae: 0.2426 - val_loss: 0.0203 - val_mae: 0.1317\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - mae: 0.0789 - val_loss: 0.0093 - val_mae: 0.0796\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - mae: 0.0514 - val_loss: 0.0041 - val_mae: 0.0462\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0447 - val_loss: 0.0036 - val_mae: 0.0418\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0033 - val_mae: 0.0404\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.0034 - val_mae: 0.0410\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0363 - val_loss: 0.0037 - val_mae: 0.0425\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0037 - val_mae: 0.0426\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0033 - val_mae: 0.0394\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0032 - val_mae: 0.0396\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0036 - val_mae: 0.0419\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0361 - val_loss: 0.0034 - val_mae: 0.0405\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 0.0032 - val_mae: 0.0393\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0034 - val_mae: 0.0410\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0413\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0033 - val_mae: 0.0397\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0348 - val_loss: 0.0038 - val_mae: 0.0446\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0032 - val_mae: 0.0393\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0337 - val_loss: 0.0045 - val_mae: 0.0505\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0360 - val_loss: 0.0032 - val_mae: 0.0411\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0032 - val_mae: 0.0408\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0351 - val_loss: 0.0032 - val_mae: 0.0398\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0360 - val_loss: 0.0035 - val_mae: 0.0421\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0034 - val_mae: 0.0413\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 0.0032 - val_mae: 0.0399\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0037 - val_mae: 0.0437\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0350 - val_loss: 0.0033 - val_mae: 0.0433\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0053 - val_mae: 0.0560\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0033 - val_mae: 0.0435\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.0039 - val_mae: 0.0462\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - mae: 0.0344 - val_loss: 0.0032 - val_mae: 0.0403\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0345 - val_loss: 0.0038 - val_mae: 0.0449\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.0032 - val_mae: 0.0405\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0339 - val_loss: 0.0032 - val_mae: 0.0406\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0034 - val_mae: 0.0414\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0033 - val_mae: 0.0407\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0346 - val_loss: 0.0033 - val_mae: 0.0409\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.0032 - val_mae: 0.0412\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0051 - val_mae: 0.0548\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0032 - val_mae: 0.0411\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0346 - val_loss: 0.0041 - val_mae: 0.0474\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0041 - val_mae: 0.0476\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0033 - val_mae: 0.0430\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0339 - val_loss: 0.0064 - val_mae: 0.0624\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0033 - val_mae: 0.0427\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0032 - val_mae: 0.0418\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0045 - val_mae: 0.0500\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0363 - val_loss: 0.0033 - val_mae: 0.0413\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0034 - val_mae: 0.0424\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0033 - val_mae: 0.0413\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0039 - val_mae: 0.0458\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 0.0035 - val_mae: 0.0426\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 0.0039 - val_mae: 0.0456\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0342 - val_loss: 0.0032 - val_mae: 0.0416\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0324 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0033 - val_mae: 0.0417\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.0033 - val_mae: 0.0417\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0048 - val_mae: 0.0525\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0033 - val_mae: 0.0421\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0032 - val_mae: 0.0425\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0032 - val_mae: 0.0424\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0033 - val_mae: 0.0431\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0034 - val_mae: 0.0427\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0041 - val_mae: 0.0476\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0033 - val_mae: 0.0426\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0033 - val_mae: 0.0436\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0033 - val_mae: 0.0440\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0341 - val_loss: 0.0033 - val_mae: 0.0422\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0325 - val_loss: 0.0034 - val_mae: 0.0426\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0039 - val_mae: 0.0457\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0033 - val_mae: 0.0422\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0032 - val_mae: 0.0422\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0042 - val_mae: 0.0486\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0034 - val_mae: 0.0431\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0331 - val_loss: 0.0033 - val_mae: 0.0421\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.0033 - val_mae: 0.0425\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0321 - val_loss: 0.0042 - val_mae: 0.0482\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0298 - val_loss: 0.0033 - val_mae: 0.0423\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0035 - val_mae: 0.0429\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0048 - val_mae: 0.0522\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0339 - val_loss: 0.0038 - val_mae: 0.0446\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.0044 - val_mae: 0.0495\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0335 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 0.0040 - val_mae: 0.0463\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0069 - val_mae: 0.0656\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0035 - val_mae: 0.0430\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0037 - val_mae: 0.0444\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0326 - val_loss: 0.0033 - val_mae: 0.0437\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0036 - val_mae: 0.0442\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0033 - val_mae: 0.0433\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0044 - val_mae: 0.0489\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0033 - val_mae: 0.0426\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0048 - val_mae: 0.0523\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0040 - val_mae: 0.0463\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0315 - val_loss: 0.0038 - val_mae: 0.0449\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0034 - val_mae: 0.0427\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0316 - val_loss: 0.0050 - val_mae: 0.0536\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0335 - val_loss: 0.0042 - val_mae: 0.0481\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - mae: 0.0559 \n",
      "Test MAE: 0.05630723387002945\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are the preprocessed input and output data\n",
    "history = dense_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = dense_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8bcdf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushikesh/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "def build_lstm_model(window_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # LSTM layer with 50 units (neurons)\n",
    "    model.add(layers.LSTM(50, activation='relu', input_shape=(window_size, 1)))\n",
    "    \n",
    "    # Optionally, you can add more LSTM layers here\n",
    "    # model.add(layers.LSTM(50, activation='relu', return_sequences=False))\n",
    "    \n",
    "    # Dense output layer (1 neuron for predicting the next time step's value)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model with Adam optimizer and MSE loss function\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: Assuming window_size is 12 (12 months), input shape will be (12, 1)\n",
    "window_size = 12\n",
    "lstm_model = build_lstm_model(window_size)\n",
    "\n",
    "# Summary of the model\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f63fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.2178 - mae: 0.4211 - val_loss: 0.1510 - val_mae: 0.3834\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0366 - mae: 0.1570 - val_loss: 0.0036 - val_mae: 0.0449\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0099 - mae: 0.0831 - val_loss: 0.0079 - val_mae: 0.0722\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - mae: 0.0649 - val_loss: 0.0052 - val_mae: 0.0551\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0593 - val_loss: 0.0035 - val_mae: 0.0401\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - mae: 0.0466 - val_loss: 0.0042 - val_mae: 0.0498\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0416 - val_loss: 0.0048 - val_mae: 0.0557\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0410 - val_loss: 0.0050 - val_mae: 0.0582\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0041 - val_mae: 0.0490\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0035 - val_mae: 0.0408\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0382 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0034 - val_mae: 0.0398\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0378 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0406 - val_loss: 0.0035 - val_mae: 0.0400\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0034 - val_mae: 0.0394\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0035 - val_mae: 0.0407\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0035 - val_mae: 0.0395\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0044 - val_mae: 0.0478\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0414 - val_loss: 0.0036 - val_mae: 0.0407\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0035 - val_mae: 0.0401\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0034 - val_mae: 0.0392\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0037 - val_mae: 0.0416\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0037 - val_mae: 0.0420\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0413 - val_loss: 0.0034 - val_mae: 0.0393\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0401 - val_loss: 0.0034 - val_mae: 0.0394\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0034 - val_mae: 0.0392\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0379 - val_loss: 0.0034 - val_mae: 0.0393\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0381 - val_loss: 0.0036 - val_mae: 0.0441\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0409 - val_loss: 0.0036 - val_mae: 0.0440\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0393 - val_loss: 0.0034 - val_mae: 0.0395\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0034 - val_mae: 0.0394\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0387 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0041 - val_mae: 0.0451\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0036 - val_mae: 0.0410\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0396 - val_loss: 0.0039 - val_mae: 0.0441\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0034 - val_mae: 0.0393\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0036 - val_mae: 0.0414\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.0034 - val_mae: 0.0393\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0034 - val_mae: 0.0395\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0042 - val_mae: 0.0463\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0410 - val_loss: 0.0045 - val_mae: 0.0489\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0047 - val_mae: 0.0512\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0422 - val_loss: 0.0034 - val_mae: 0.0395\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0394 - val_loss: 0.0034 - val_mae: 0.0394\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0399 - val_loss: 0.0034 - val_mae: 0.0394\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0035 - val_mae: 0.0401\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0388 - val_loss: 0.0034 - val_mae: 0.0394\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0040 - val_mae: 0.0448\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0043 - val_mae: 0.0476\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0035 - val_mae: 0.0433\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0414 - val_loss: 0.0036 - val_mae: 0.0412\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0400 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0367 - val_loss: 0.0034 - val_mae: 0.0395\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0385 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0043 - val_mae: 0.0468\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0038 - val_mae: 0.0433\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0045 - val_mae: 0.0489\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0042 - val_mae: 0.0464\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0394 - val_loss: 0.0034 - val_mae: 0.0395\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0375 - val_loss: 0.0040 - val_mae: 0.0449\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0366 - val_loss: 0.0035 - val_mae: 0.0421\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0034 - val_mae: 0.0395\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0418 - val_loss: 0.0035 - val_mae: 0.0402\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0036 - val_mae: 0.0408\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0040 - val_mae: 0.0451\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0047 - val_mae: 0.0505\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0034 - val_mae: 0.0397\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0034 - val_mae: 0.0397\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0036 - val_mae: 0.0410\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0040 - val_mae: 0.0446\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0388 - val_loss: 0.0034 - val_mae: 0.0399\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0347 - val_loss: 0.0035 - val_mae: 0.0402\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0348 - val_loss: 0.0051 - val_mae: 0.0545\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0389 - val_loss: 0.0039 - val_mae: 0.0438\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0037 - val_mae: 0.0417\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0385 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0035 - val_mae: 0.0401\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0035 - val_mae: 0.0405\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0044 - val_mae: 0.0483\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0389 - val_loss: 0.0045 - val_mae: 0.0492\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0034 - val_mae: 0.0401\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0405 - val_loss: 0.0051 - val_mae: 0.0541\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0055 - val_mae: 0.0574\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0034 - val_mae: 0.0397\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0413 - val_loss: 0.0037 - val_mae: 0.0425\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - mae: 0.0477 \n",
      "Test MAE: 0.04820504039525986\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are preprocessed and windowed for LSTM input\n",
    "history = lstm_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = lstm_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcbeff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train, X_val, and X_test for LSTM input\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val_lstm = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d12891ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushikesh/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m16,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,293</span> (63.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,293\u001b[0m (63.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,293</span> (63.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,293\u001b[0m (63.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Conv1D model architecture\n",
    "def build_conv1d_model(window_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Conv1D layer with 64 filters, kernel size of 2, and ReLU activation\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(window_size, 1)))\n",
    "    \n",
    "    # MaxPooling1D layer to reduce dimensionality (optional)\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Flatten the output before feeding into Dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Dense hidden layer with 50 units and ReLU activation\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    \n",
    "    # Output layer (1 neuron for predicting the next time step's value)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model with Adam optimizer and MSE loss\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example: Assuming window_size is 12 (12 months)\n",
    "window_size = 12\n",
    "conv1d_model = build_conv1d_model(window_size)\n",
    "\n",
    "# Summary of the model\n",
    "conv1d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "083f93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.2019 - mae: 0.3822 - val_loss: 0.0071 - val_mae: 0.0734\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0898 - val_loss: 0.0097 - val_mae: 0.0826\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - mae: 0.0501 - val_loss: 0.0039 - val_mae: 0.0449\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0394 - val_loss: 0.0036 - val_mae: 0.0431\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0400 - val_loss: 0.0038 - val_mae: 0.0445\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0036 - val_mae: 0.0428\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0035 - val_mae: 0.0423\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0043 - val_mae: 0.0482\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0048 - val_mae: 0.0523\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0040 - val_mae: 0.0457\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0042 - val_mae: 0.0477\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mae: 0.0411 - val_loss: 0.0040 - val_mae: 0.0455\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0041 - val_mae: 0.0464\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0036 - val_mae: 0.0429\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0055 - val_mae: 0.0571\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0394 - val_loss: 0.0042 - val_mae: 0.0475\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0408 - val_loss: 0.0034 - val_mae: 0.0415\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0381 - val_loss: 0.0034 - val_mae: 0.0414\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0412 - val_loss: 0.0040 - val_mae: 0.0457\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0034 - val_mae: 0.0414\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0039 - val_mae: 0.0453\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0397 - val_loss: 0.0047 - val_mae: 0.0510\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0046 - val_mae: 0.0505\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0402 - val_loss: 0.0042 - val_mae: 0.0476\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0036 - val_mae: 0.0432\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0036 - val_mae: 0.0433\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0050 - val_mae: 0.0540\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0039 - val_mae: 0.0452\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0038 - val_mae: 0.0443\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0037 - val_mae: 0.0439\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0037 - val_mae: 0.0436\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0047 - val_mae: 0.0517\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0402 - val_loss: 0.0040 - val_mae: 0.0460\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0396 - val_loss: 0.0044 - val_mae: 0.0489\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0043 - val_mae: 0.0479\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0049 - val_mae: 0.0531\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0039 - val_mae: 0.0457\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0414 - val_loss: 0.0043 - val_mae: 0.0487\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 0.0037 - val_mae: 0.0443\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0038 - val_mae: 0.0451\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0350 - val_loss: 0.0036 - val_mae: 0.0432\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 0.0043 - val_mae: 0.0481\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0055 - val_mae: 0.0577\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0055 - val_mae: 0.0575\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0037 - val_mae: 0.0439\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0036 - val_mae: 0.0433\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0388 - val_loss: 0.0034 - val_mae: 0.0418\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0388 - val_loss: 0.0035 - val_mae: 0.0440\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0405 - val_loss: 0.0034 - val_mae: 0.0428\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0384 - val_loss: 0.0044 - val_mae: 0.0489\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mae: 0.0349 - val_loss: 0.0047 - val_mae: 0.0516\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0038 - val_mae: 0.0447\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0037 - val_mae: 0.0441\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0374 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0036 - val_mae: 0.0453\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - mae: 0.0416 - val_loss: 0.0044 - val_mae: 0.0493\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0394 - val_loss: 0.0037 - val_mae: 0.0441\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0357 - val_loss: 0.0045 - val_mae: 0.0502\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0396 - val_loss: 0.0034 - val_mae: 0.0418\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0035 - val_mae: 0.0426\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0042 - val_mae: 0.0479\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0368 - val_loss: 0.0059 - val_mae: 0.0597\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0037 - val_mae: 0.0442\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - mae: 0.0348 - val_loss: 0.0045 - val_mae: 0.0497\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0034 - val_mae: 0.0427\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0372 - val_loss: 0.0036 - val_mae: 0.0435\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0037 - val_mae: 0.0439\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 0.0036 - val_mae: 0.0437\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0035 - val_mae: 0.0423\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0354 - val_loss: 0.0034 - val_mae: 0.0419\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0048 - val_mae: 0.0525\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0040 - val_mae: 0.0465\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0037 - val_mae: 0.0439\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0037 - val_mae: 0.0442\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0368 - val_loss: 0.0054 - val_mae: 0.0567\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0036 - val_mae: 0.0438\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0341 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0036 - val_mae: 0.0439\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0378 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0054 - val_mae: 0.0562\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0043 - val_mae: 0.0489\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0040 - val_mae: 0.0462\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - mae: 0.0335 - val_loss: 0.0037 - val_mae: 0.0442\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0037 - val_mae: 0.0441\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0349 - val_loss: 0.0044 - val_mae: 0.0496\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0368 - val_loss: 0.0041 - val_mae: 0.0471\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0043 - val_mae: 0.0490\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0036 - val_mae: 0.0437\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0371 - val_loss: 0.0036 - val_mae: 0.0439\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0048 - val_mae: 0.0522\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0359 - val_loss: 0.0041 - val_mae: 0.0469\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0035 - val_mae: 0.0425\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mae: 0.0359 - val_loss: 0.0055 - val_mae: 0.0569\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0042 - val_mae: 0.0483\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0348 - val_loss: 0.0035 - val_mae: 0.0447\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0435 - val_loss: 0.0046 - val_mae: 0.0512\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0035 - val_mae: 0.0428\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - mae: 0.0481 \n",
      "Test MAE: 0.04882214218378067\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train and y_train are preprocessed and windowed for Conv1D input\n",
    "history = conv1d_model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_mae = conv1d_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b9da0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_train, X_val, and X_test for Conv1D input\n",
    "X_train_conv1d = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val_conv1d = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test_conv1d = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e7a4cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming y_test and y_pred are available for each model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Example for Dense model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m y_pred_dense \u001b[38;5;241m=\u001b[39m dense_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m---> 12\u001b[0m mae_dense, mse_dense, rmse_dense, r2_dense \u001b[38;5;241m=\u001b[39m calculate_metrics(y_test, y_pred_dense)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Example for LSTM model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m y_pred_lstm \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_metrics\u001b[39m(y_true, y_pred):\n\u001b[0;32m----> 2\u001b[0m     mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_true, y_pred)\n\u001b[1;32m      3\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_true, y_pred)\n\u001b[1;32m      4\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return mae, mse, rmse, r2\n",
    "\n",
    "# Assuming y_test and y_pred are available for each model\n",
    "# Example for Dense model\n",
    "y_pred_dense = dense_model.predict(X_test)\n",
    "mae_dense, mse_dense, rmse_dense, r2_dense = calculate_metrics(y_test, y_pred_dense)\n",
    "\n",
    "# Example for LSTM model\n",
    "y_pred_lstm = lstm_model.predict(X_test)\n",
    "mae_lstm, mse_lstm, rmse_lstm, r2_lstm = calculate_metrics(y_test, y_pred_lstm)\n",
    "\n",
    "# Example for Conv1D model\n",
    "y_pred_conv1d = conv1d_model.predict(X_test)\n",
    "mae_conv1d, mse_conv1d, rmse_conv1d, r2_conv1d = calculate_metrics(y_test, y_pred_conv1d)\n",
    "\n",
    "# Print or store the results for comparison\n",
    "print(f\"Dense Model - MAE: {mae_dense}, MSE: {mse_dense}, RMSE: {rmse_dense}, R2: {r2_dense}\")\n",
    "print(f\"LSTM Model - MAE: {mae_lstm}, MSE: {mse_lstm}, RMSE: {rmse_lstm}, R2: {r2_lstm}\")\n",
    "print(f\"Conv1D Model - MAE: {mae_conv1d}, MSE: {mse_conv1d}, RMSE: {rmse_conv1d}, R2: {r2_conv1d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71604449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
